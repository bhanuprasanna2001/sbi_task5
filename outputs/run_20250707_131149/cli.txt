Don't edit, but dig deep reserach and analyze completely please and provide a very detailed analysis please:

I have the following terminal output, I don't know why the advanced bayesflow diagnostics is bad or is it fine? The Human insulin validation also there is a problem, please dig deep analysis please and give me proper insights:

python scripts/train_bayesflow.py
2025-07-07 13:11:48.872478: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to:
 Apple M1 Pro                                                                                   2025-07-07 13:11:48.872517: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 G
B                                                                                               2025-07-07 13:11:48.872525: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1751886708.872541 1813747 pluggable_device_factory.cc:305] Could not identify NUMA n
ode of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.                                                                                               I0000 00:00:1751886708.872590 1813747 pluggable_device_factory.cc:271] Created TensorFlow device
 (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)                                                  INFO:bayesflow:Using backend 'tensorflow'
INFO:src.hmm.protein_hmm:Set fixed HMM parameters from task specification
INFO:src.hmm.protein_hmm:Initialized ProteinHMM with 2 states and 20 amino acids
INFO:src.hmm.protein_hmm:Set fixed HMM parameters from task specification
INFO:src.hmm.protein_hmm:Initialized ProteinHMM with 2 states and 20 amino acids
============================================================
BAYESFLOW PROTEIN SECONDARY STRUCTURE TRAINING
============================================================
INFO:src.utils.visualization:Created run directory: outputs/run_20250707_131149
ğŸ“ Output directory: outputs/run_20250707_131149
INFO:src.utils.visualization:Saved run config to outputs/run_20250707_131149/config.json
Configuration:
  sequence_length: 100
  num_total_samples: 20000
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  batch_size: 64
  epochs: 50
  num_posterior_samples: 2000
  learning_rate: 0.0001
  early_stopping_patience: 15
  keras_backend: tensorflow
Data split: Train=14000, Val=3000, Test=3000

Creating BayesFlow simulator...
INFO:src.hmm.protein_hmm:Set fixed HMM parameters from task specification
INFO:src.hmm.protein_hmm:Initialized ProteinHMM with 2 states and 20 amino acids
Testing simulator...
Simulator output keys: ['sequence', 'state_probs']
Sequence shape: (3, 100)
State probs shape: (3, 200)

Creating data adapter...
Adapted keys: ['inference_variables', 'summary_variables']
Summary variables shape: (3, 100, 1)
Inference variables shape: (3, 200)

Generating complete dataset...
Training data: 14000 samples
Validation data: 3000 samples
Test data: 3000 samples

Creating inference network...
Creating BayesFlow workflow...

Starting training for up to 50 epochs...
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
Epoch 1/50
2025-07-07 13:12:07.809862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registr
y.cc:117] Plugin optimizer for device_type GPU is enabled.                                      219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 36s 117ms/step - loss: 4.7873 - val_loss: 1.4991
Epoch 2/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 108ms/step - loss: 1.3851 - val_loss: 1.1258
Epoch 3/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23s 107ms/step - loss: 1.1016 - val_loss: 1.0092
Epoch 4/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 108ms/step - loss: 0.9991 - val_loss: 0.9473
Epoch 5/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.9497 - val_loss: 0.9119
Epoch 6/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 115ms/step - loss: 0.9154 - val_loss: 0.8823
Epoch 7/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.8906 - val_loss: 0.8617
Epoch 8/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 111ms/step - loss: 0.8741 - val_loss: 0.8407
Epoch 9/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.8599 - val_loss: 0.8322
Epoch 10/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.8469 - val_loss: 0.8237
Epoch 11/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 122ms/step - loss: 0.8367 - val_loss: 0.8160
Epoch 12/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 29s 130ms/step - loss: 0.8281 - val_loss: 0.8045
Epoch 13/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 123ms/step - loss: 0.8219 - val_loss: 0.8020
Epoch 14/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.8155 - val_loss: 0.7907
Epoch 15/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.8083 - val_loss: 0.7885
Epoch 16/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 124ms/step - loss: 0.8053 - val_loss: 0.7885
Epoch 17/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 122ms/step - loss: 0.8020 - val_loss: 0.7830
Epoch 18/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 123ms/step - loss: 0.7973 - val_loss: 0.7829
Epoch 19/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 26s 118ms/step - loss: 0.7946 - val_loss: 0.7729
Epoch 20/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 114ms/step - loss: 0.7920 - val_loss: 0.7694
Epoch 21/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 110ms/step - loss: 0.7901 - val_loss: 0.7749
Epoch 22/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.7880 - val_loss: 0.7731
Epoch 23/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.7856 - val_loss: 0.7696
Epoch 24/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 112ms/step - loss: 0.7841 - val_loss: 0.7722
Epoch 25/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 111ms/step - loss: 0.7834 - val_loss: 0.7715
Epoch 26/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 114ms/step - loss: 0.7830 - val_loss: 0.7638
Epoch 27/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 114ms/step - loss: 0.7812 - val_loss: 0.7715
Epoch 28/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.7797 - val_loss: 0.7699
Epoch 29/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.7778 - val_loss: 0.7657
Epoch 30/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23s 106ms/step - loss: 0.7773 - val_loss: 0.7624
Epoch 31/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23s 106ms/step - loss: 0.7780 - val_loss: 0.7638
Epoch 32/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23s 107ms/step - loss: 0.7771 - val_loss: 0.7674
Epoch 33/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.7775 - val_loss: 0.7653
Epoch 34/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 112ms/step - loss: 0.7755 - val_loss: 0.7651
Epoch 35/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 110ms/step - loss: 0.7734 - val_loss: 0.7678
Epoch 36/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 114ms/step - loss: 0.7745 - val_loss: 0.7616
Epoch 37/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.7739 - val_loss: 0.7627
Epoch 38/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.7730 - val_loss: 0.7640
Epoch 39/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 113ms/step - loss: 0.7728 - val_loss: 0.7636
Epoch 40/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 116ms/step - loss: 0.7744 - val_loss: 0.7635
Epoch 41/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 116ms/step - loss: 0.7726 - val_loss: 0.7611
Epoch 42/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 121ms/step - loss: 0.7720 - val_loss: 0.7644
Epoch 43/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 114ms/step - loss: 0.7725 - val_loss: 0.7613
Epoch 44/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27s 121ms/step - loss: 0.7742 - val_loss: 0.7590
Epoch 45/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 108ms/step - loss: 0.7737 - val_loss: 0.7624
Epoch 46/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 110ms/step - loss: 0.7701 - val_loss: 0.7611
Epoch 47/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 110ms/step - loss: 0.7707 - val_loss: 0.7621
Epoch 48/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 109ms/step - loss: 0.7716 - val_loss: 0.7639
Epoch 49/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24s 111ms/step - loss: 0.7725 - val_loss: 0.7607
Epoch 50/50
219/219 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 112ms/step - loss: 0.7719 - val_loss: 0.7634
âœ“ Training completed!

Plotting training results...
ğŸ“Š Training plot saved: outputs/run_20250707_131149/figures/training_loss.png

Running posterior sampling on test data...
Posterior samples keys: ['state_probs']
Posterior samples shape: (3000, 2000, 200)

Saving complete dataset...
ğŸ’¾ Data saved: outputs/run_20250707_131149/data/complete_dataset.npz

============================================================
ADVANCED BAYESFLOW DIAGNOSTICS
============================================================
Computing comprehensive BayesFlow diagnostics...
Sampling from posterior...
Sampling from prior...
Analyzing 3000 test sequences of length 100

=== COMPREHENSIVE DIAGNOSTICS SUMMARY ===
Posterior Contraction (mean): 0.000000
Calibration Error (mean): 0.212500
NRMSE (mean, finite values): 0.000000
NRMSE (median, finite values): 0.000000

Problematic cases:
  Low posterior contraction (<0.1): 5000/5000 (100.0%)
  High calibration error (>0.1): 5000/5000 (100.0%)
  High NRMSE (>1.0): 0/5000 (0.0% of finite values)
ğŸ“Š Advanced diagnostics saved: outputs/run_20250707_131149/reports/advanced_diagnostics.csv
Diagnostic plot saved to outputs/run_20250707_131149/figures/advanced_diagnostics.png
ğŸ“‹ Training recommendations saved: outputs/run_20250707_131149/reports/training_recommendations.
json                                                                                            
ğŸ¯ TRAINING ASSESSMENT:
   Priority: CRITICAL
   Status: TRAINING_FAILED
   Immediate Actions Required:
     â€¢ Stop current training approach
     â€¢ Review data preprocessing pipeline
     â€¢ Verify BayesFlow adapter configuration
     â€¢ Check for data leakage or preprocessing errors

============================================================

============================================================
TASK 5 REQUIREMENT: HUMAN INSULIN VALIDATION
============================================================

============================================================
HUMAN INSULIN VALIDATION
============================================================
Insulin sequence length: 51
Alpha-helix residues: 22/51 (43.1%)
Generating posterior predictions for insulin...

ğŸ§¬ HUMAN INSULIN RESULTS:
  Overall Accuracy: 0.5686
  Alpha-helix Accuracy: 0.0000
  Other Structure Accuracy: 1.0000
  Precision: 0.0000
  Recall: 0.0000
  F1-Score: 0.0000
ğŸ“Š Insulin validation plot saved: outputs/run_20250707_131149/figures/insulin_validation.png
ğŸ“Š Insulin validation saved: outputs/run_20250707_131149/reports/insulin_validation.json

ğŸ“š LITERATURE COMPARISON:
  âŒ Agreement with DSSP annotations: 0.569 (outside range 0.70-0.85)
  âŒ Traditional HMM methods: 0.569 (outside range 0.65-0.75)
  âŒ Modern neural network methods: 0.569 (outside range 0.75-0.85)
  âŒ Bayesian inference methods: 0.569 (outside range 0.70-0.80)

============================================================

Evaluating model accuracy...

ğŸ¯ ACCURACY RESULTS (evaluated on 50 sequences):
  Overall Accuracy: 1.0000
  Alpha-helix Accuracy: 1.0000
  Other Structure Accuracy: 1.0000
  Precision: 1.0000
  Recall: 1.0000
  F1-Score: 1.0000
  Average MSE: 0.000000
ğŸ“Š Results saved: outputs/run_20250707_131149/reports/results.json

Creating model-specific visualizations...
ğŸ“Š Model analysis plot saved: outputs/run_20250707_131149/figures/model_analysis.png

Saving trained model...
ğŸ’¾ Model saved: outputs/run_20250707_131149/models/bayesflow_model.keras

============================================================
TRAINING COMPLETED SUCCESSFULLY!
ğŸ“ All outputs saved to: outputs/run_20250707_131149
============================================================
